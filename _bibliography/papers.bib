---
---

@inproceedings{rennie-etal-2020-unsupervised,
    title = "Unsupervised Adaptation of Question Answering Systems via Generative Self-training",
    author = "Rennie, Steven  and
      Marcheret, Etienne  and
      Mallinar, Neil  and
      Nahamoo, David  and
      Goel, Vaibhava",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.87",
    doi = "10.18653/v1/2020.emnlp-main.87",
    pages = "1148--1157",
    abstract = "BERT-era question answering systems have recently achieved impressive performance on several question-answering (QA) tasks. These systems are based on representations that have been pre-trained on self-supervised tasks such as word masking and sentence entailment, using massive amounts of data. Nevertheless, additional pre-training closer to the end-task, such as training on synthetic QA pairs, has been shown to improve performance. While recent work has considered augmenting labelled data and leveraging large unlabelled datasets to generate synthetic QA data, directly adapting to target data has received little attention. In this paper we investigate the iterative generation of synthetic QA pairs as a way to realize unsupervised self adaptation. Motivated by the success of the roundtrip consistency method for filtering generated QA pairs, we present iterative generalizations of the approach, which maximize an approximation of a lower bound on the probability of the adaptation data. By adapting on synthetic QA pairs generated on the target data, our method is able to improve QA systems significantly, using an order of magnitude less synthetic data and training computation than existing augmentation approaches.",
    selected = {true}
}


@article{mallinar_iterative_2020,
  title = {Iterative {Data} {Programming} for {Expanding} {Text} {Classification} {Corpora}},
  volume = {34},
  copyright = {All rights reserved},
  url = {http://arxiv.org/abs/2002.01412},
  abstract = {Real-world text classification tasks often require many labeled training examples that are expensive to obtain. Recent advancements in machine teaching, specifically the data programming paradigm, facilitate the creation of training data sets quickly via a general framework for building weak models, also known as labeling functions, and denoising them through ensemble learning techniques. We present a fast, simple data programming method for augmenting text data sets by generating neighborhood-based weak models with minimal supervision. Furthermore, our method employs an iterative procedure to identify sparsely distributed examples from large volumes of unlabeled data. The iterative data programming techniques improve newer weak models as more labeled data is confirmed with human-in-loop. We show empirical results on sentence classification tasks, including those from a task of improving intent recognition in conversational agents.},
  urldate = {2020-02-06},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author = {Mallinar, Neil and Shah, Abhishek and Ho, Tin Kam and Ugrani, Rajendra and Gupta, Ayush},
  month = feb,
  year = {2020},
  note = {arXiv: 2002.01412},
  annote = {Comment: 6 pages, 2 figures, In Proceedings of the AAAI Conference on Artificial Intelligence 2020 (IAAI Technical Track: Emerging Papers)},
  annote = {Extracted Annotations (2/6/2020, 5:05:14 PM)
"It is even more challenging when the classes are highly skewed, which renders a sequential process to look for each class largely ineffective, as examples of the minority class are buried in much larger amounts of data of other classes." (Mallinar et al 2020:1)
"Guided learning approaches aim to lessen the amount of data to be labeled, by using search to select relevant examples for labeling, and are shown to be more effective than random labeling and active learning techniques in settings where data exhibits high skew" (Mallinar et al 2020:2)
"We distinguish our work from active learning frameworks as in (Settles 2009) by that we never access or query the" (Mallinar et al 2020:2)
"downstream learner during our procedure. Often such learners require a decent amount of data and tuning on validation sets to be effective models. In our setting, the amount of labeled data provided at the start is very limited ({\textless} 20 examples per class) to the point that even a validation set is impossible to extract." (Mallinar et al 2020:3)
"Our procedure repeats a basic step that consists of leveraging the labeled examples to rank and select the unlabeled examples, and then consulting an oracle for labeling the selected ones. In each step the selection is limited in size to minimize consumption of the oracle resources. This procedure continues until a termination criteria is reached." (Mallinar et al 2020:3)
"For multi-class data, we simply apply the same expansion process independently for each class and merge the resultant positive labeled sets to get our final expanded training set to avoid extreme data skew that might be caused by intermediate steps prior to the completion of expansion of all the classes." (Mallinar et al 2020:3)
"The labeler can be expensive to evaluate in practice (often a domain expert), so we include a batch size setting that restrict the periteration labeling effort, and a termination criteria to determine when to stop expanding the data." (Mallinar et al 2020:3)
"This is repeated until a termination criteria, parameterized by t, is met. We define t to be the maximum number of consecutive examples we are willing to send to the labeler, in each iteration, without receiving any positive labels back. We consider the data to be fully expanded when we reach this point. In this work, we use t = 30 and b = 10 to simulate a user looking through three pages of relevant examples with ten examples per page before quitting." (Mallinar et al 2020:3)
"Here we use the "More Like This" (MLT) feature of the search engine Elasticsearch 1 to expand batches of examples and rank them based on the returned score. As such, this selection model only uses positively labeled data for expansion and does not make use of negative labels." (Mallinar et al 2020:3)
"We note that while this work uses lexical matching to build neighborhoods, the way we construct weak models can be generalized to any reasonable way to define a subset in a metric space." (Mallinar et al 2020:4)
"In the medium density setting, a probabilistic generative model p (; Y ) is trained over and the true labels, Y , of the examples. It is shown that in the medium density setting, such a model can better denoise the assignments between weak models than a simple majority vote." (Mallinar et al 2020:4)
"We construct weak models with two independent MLT expansions on the newly labeled positive and negative examples obtained at each iteration." (Mallinar et al 2020:4)
"This automatic construction of weak models eliminates the need for domain experts to encode relevant heuristics about the classes, or the need for many crowdsourced workers. Instead, a single labeler can quickly label a small number of examples over a few iterations and generate a larger label matrix, ." (Mallinar et al 2020:4)
"After training the generative model, we finally retrieve a list of computed probabilistic labels over examples in our unlabeled corpus (where we default to a score of 0 for those examples that are not covered by at least one weak model). These probabilistic labels are used to rank examples for selection in future iterations of Algorithm 1." (Mallinar et al 2020:4)
"This merging scheme ensures that at each iteration there is an expansion method that reflects the latest qualities of the labeled data (search), as well as an expansion method that produces stronger, less noisy rankings at the cost of being slightly outdated relative to the current set of labeled data (data programming)." (Mallinar et al 2020:4)
"Our experience indicates that most users can afford to hand-write or hand-select a very small set of examples per class. So we hand-select such examples as the initial training set in our experiments." (Mallinar et al 2020:4)
"The final Reddit dataset consists of 810 labeled titles to start with, 63,990 unlabeled titles and 16,200 titles as test set." (Mallinar et al 2020:4)
"The English data set, CS-En, is split into an unlabeled corpus of 15,236 examples, initially labeled set of size 1,998, and test set of size 15,177 spanning 97 categories." (Mallinar et al 2020:4)
"we start with the initial labeled set and expand each class independently as described in Algorithm 1. After the expansion procedure finishes for each class, we combine all of the fully expanded classes together to create the final labeled training data set" (Mallinar et al 2020:5)
"we train a text classifier 3 on this labeled set and evaluate accuracy on the held-out test set. This accuracy is called the terminal accuracy for the given method used in expansion. We compare the terminal accuracy to the optimal accuracy, which is obtained by training the same classifier on using the ground truth for the entire corpus from which the examples are selected, and evaluating on the test set." (Mallinar et al 2020:5)
"apid ascent than I-MLT, and are able to continue to find useful examples for many more rounds before hitting the termination condition. This can be seen more clearly for the class "videogame controller", where I-MLT seems to converge earlier and reach a recall asymptote whereas I-DP, at the same number of examples sent for labeling, continues to expand." (Mallinar et al 2020:6)
"For instance, the method assumes that the full scope of a class can be reached through chains of neighbors. When this is not true with heavily fragmented classes, we need alternative ways to scatter some seeds to every fragment, by randomization or in-depth analysis of the data characteristics." (Mallinar et al 2020:6)},
  file = {Mallinar et al_2020_Iterative Data Programming for Expanding Text Classification Corpora.pdf:/Users/nmallinar/Google Drive/Research/ZoteroSync/Mallinar et al_2020_Iterative Data Programming for Expanding Text Classification Corpora.pdf:application/pdf},
}

@article{chen_big-little_2019,
  title = {Big-{Little} {Net}: {An} {Efficient} {Multi}-{Scale} {Feature} {Representation} for {Visual} and {Speech} {Recognition}},
  copyright = {All rights reserved},
  shorttitle = {Big-{Little} {Net}},
  url = {http://arxiv.org/abs/1807.03848},
  abstract = {In this paper, we propose a novel Convolutional Neural Network (CNN) architecture for learning multi-scale feature representations with good tradeoffs between speed and accuracy. This is achieved by using a multi-branch network, which has different computational complexity at different branches. Through frequent merging of features from branches at distinct scales, our model obtains multi-scale features while using less computation. The proposed approach demonstrates improvement of model efficiency and performance on both object recognition and speech recognition tasks,using popular architectures including ResNet and ResNeXt. For object recognition, our approach reduces computation by 33\% on object recognition while improving accuracy with 0.9\%. Furthermore, our model surpasses state-of-the-art CNN acceleration approaches by a large margin in accuracy and FLOPs reduction. On the task of speech recognition, our proposed multi-scale CNNs save 30\% FLOPs with slightly better word error rates, showing good generalization across domains. The codes are available at https://github.com/IBM/BigLittleNet},
  urldate = {2019-10-04},
  journal = {International Conference on Learning Representations},
  author = {Chen, Chun-Fu and Fan, Quanfu and Mallinar, Neil and Sercu, Tom and Feris, Rogerio},
  year = {2019},
  note = {arXiv: 1807.03848},
  annote = {Comment: git repo: https://github.com/IBM/BigLittleNet},
  file = {Chen et al_2019_Big-Little Net - An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition.pdf:/Users/nmallinar/Google Drive/Research/ZoteroSync/Chen et al_2019_Big-Little Net - An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition.pdf:application/pdf},
  selected = {true}
}

@misc{sercu2019multiframe,
      title={Multi-Frame Cross-Entropy Training for Convolutional Neural Networks in Speech Recognition},
      author={Tom Sercu and Neil Mallinar},
      year={2019},
      eprint={1907.13121},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@article{mallinar_bootstrapping_2018,
  title = {Bootstrapping {Conversational} {Agents} {With} {Weak} {Supervision}},
  volume = {33},
  copyright = {All rights reserved},
  url = {http://arxiv.org/abs/1812.06176},
  abstract = {Many conversational agents in the market today follow a standard bot development framework which requires training intent classifiers to recognize user input. The need to create a proper set of training examples is often the bottleneck in the development process. In many occasions agent developers have access to historical chat logs that can provide a good quantity as well as coverage of training examples. However, the cost of labeling them with tens to hundreds of intents often prohibits taking full advantage of these chat logs. In this paper, we present a framework called {\textbackslash}textit\{search, label, and propagate\} (SLP) for bootstrapping intents from existing chat logs using weak supervision. The framework reduces hours to days of labeling effort down to minutes of work by using a search engine to find examples, then relies on a data programming approach to automatically expand the labels. We report on a user study that shows positive user feedback for this new approach to build conversational agents, and demonstrates the effectiveness of using data programming for auto-labeling. While the system is developed for training conversational agents, the framework has broader application in significantly reducing labeling effort for training text classifiers.},
  urldate = {2019-10-04},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author = {Mallinar, Neil and Shah, Abhishek and Ugrani, Rajendra and Gupta, Ayush and Gurusankar, Manikandan and Ho, Tin Kam and Liao, Q. Vera and Zhang, Yunfeng and Bellamy, Rachel K. E. and Yates, Robert and Desmarais, Chris and McGregor, Blake},
  month = dec,
  year = {2018},
  note = {arXiv: 1812.06176},
  pages = {9528--9533},
  annote = {Comment: 6 pages, 3 figures, 1 table, Accepted for publication in IAAI 2019},
  file = {Mallinar et al_2018_Bootstrapping Conversational Agents With Weak Supervision.pdf:/Users/nmallinar/Google Drive/Research/ZoteroSync/Mallinar et al_2018_Bootstrapping Conversational Agents With Weak Supervision.pdf:application/pdf},
  selected = {true}
}

@article{mallinar_deep_2018,
  title = {Deep {Canonically} {Correlated} {LSTMs}},
  copyright = {All rights reserved},
  url = {http://arxiv.org/abs/1801.05407},
  abstract = {We examine Deep Canonically Correlated LSTMs as a way to learn nonlinear transformations of variable length sequences and embed them into a correlated, fixed dimensional space. We use LSTMs to transform multi-view time-series data non-linearly while learning temporal relationships within the data. We then perform correlation analysis on the outputs of these neural networks to find a correlated subspace through which we get our final representation via projection. This work follows from previous work done on Deep Canonical Correlation (DCCA), in which deep feed-forward neural networks were used to learn nonlinear transformations of data while maximizing correlation.},
  urldate = {2019-10-04},
  journal = {The Johns Hopkins University Bachelors Thesis},
  author = {Mallinar, Neil and Rosset, Corbin},
  month = jan,
  year = {2018},
  note = {arXiv: 1801.05407},
  annote = {Comment: 8 pages, 3 figures, accepted as the undergraduate honors thesis for Neil Mallinar by The Johns Hopkins University},
  file = {Mallinar_Rosset_2018_Deep Canonically Correlated LSTMs.pdf:/Users/nmallinar/Google Drive/Research/ZoteroSync/Mallinar_Rosset_2018_Deep Canonically Correlated LSTMs.pdf:application/pdf},
}

@article{mallinar_probabilistic_2017,
  title = {Probabilistic {Cross}-{Identification} of {Galaxies} with {Realistic} {Clustering}},
  volume = {20},
  copyright = {All rights reserved},
  issn = {22131337},
  url = {http://arxiv.org/abs/1706.09546},
  doi = {10/gb4453},
  abstract = {Probabilistic cross-identification has been successfully applied to a number of problems in astronomy from matching simple point sources to associating stars with unknown proper motions and even radio observations with realistic morphology. Here we study the Bayes factor for clustered objects and focus in particular on galaxies to assess the effect of typical angular correlations. Numerical calculations provide the modified relationship, which (as expected) suppresses the evidence for the associations at the shortest separations where the 2-point auto-correlation function is large. Ultimately this means that the matching probability drops at somewhat shorter scales than in previous models.},
  urldate = {2019-10-04},
  journal = {Astronomy and Computing},
  author = {Mallinar, Neil and Budavari, Tamas and Lemson, Gerard},
  month = jul,
  year = {2017},
  note = {arXiv: 1706.09546},
  pages = {83--86},
  annote = {Comment: Accepted for publication in Astronomy and Computing, 6 pages, 3 figures},
  file = {Mallinar et al_2017_Probabilistic Cross-Identification of Galaxies with Realistic Clustering.pdf:/Users/nmallinar/Google Drive/Research/ZoteroSync/Mallinar et al_2017_Probabilistic Cross-Identification of Galaxies with Realistic Clustering.pdf:application/pdf},
  selected = {true}
}
